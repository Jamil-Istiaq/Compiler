{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n\nimport os\nimport cv2\nfrom os import walk\nimport glob as gb\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-12T04:10:36.174848Z","iopub.execute_input":"2021-12-12T04:10:36.17541Z","iopub.status.idle":"2021-12-12T04:10:42.150385Z","shell.execute_reply.started":"2021-12-12T04:10:36.175304Z","shell.execute_reply":"2021-12-12T04:10:42.149568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 1000\nIMG_SIZE = 224\nBATCH_SIZE = 128\n\nTRAIN_DIR = '../input/gender-classification-from-an-image/gender_rev2/train'\nVALID_DIR = '../input/gender-classification-from-an-image/gender_rev2/valid'\nTEST_DIR = '../input/gender-classification-from-an-image/gender_rev2/test'","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:42.15228Z","iopub.execute_input":"2021-12-12T04:10:42.152555Z","iopub.status.idle":"2021-12-12T04:10:42.160565Z","shell.execute_reply.started":"2021-12-12T04:10:42.152516Z","shell.execute_reply":"2021-12-12T04:10:42.158364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = []\nclass_count = []\nTRAIN_EXAMPLES = 0\nfor folder in  os.listdir(TRAIN_DIR) : \n    files = gb.glob(pathname= str( TRAIN_DIR + '//' + folder + '/*'))\n    class_names.append(folder)\n    class_count.append(len(files))\n    TRAIN_EXAMPLES += len(files)\n\nplt.figure(figsize=(25,10))    \nsns.barplot(x = class_names, y=class_count).set_title(\"Distribution across classes in training set\")\nplt.show()\n\nprint(f'Total Train Examples = {TRAIN_EXAMPLES}')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:42.16285Z","iopub.execute_input":"2021-12-12T04:10:42.163356Z","iopub.status.idle":"2021-12-12T04:10:42.642428Z","shell.execute_reply.started":"2021-12-12T04:10:42.163303Z","shell.execute_reply":"2021-12-12T04:10:42.64174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = []\nclass_count = []\nTest_EXAMPLES = 0\nfor folder in  os.listdir(TEST_DIR) : \n    files = gb.glob(pathname= str( TEST_DIR + '//' + folder + '/*'))\n    class_names.append(folder)\n    class_count.append(len(files))\n    Test_EXAMPLES += len(files)\n\nplt.figure(figsize=(25,10))     \nsns.barplot(x = class_names, y=class_count).set_title(\"Distribution across classes in Test set\")\nplt.show()\n\nprint(f'Total Train Examples = {Test_EXAMPLES}')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:42.644442Z","iopub.execute_input":"2021-12-12T04:10:42.645824Z","iopub.status.idle":"2021-12-12T04:10:42.855133Z","shell.execute_reply.started":"2021-12-12T04:10:42.645783Z","shell.execute_reply":"2021-12-12T04:10:42.854443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = []\nclass_count = []\nVALIDATION_EXAMPLES = 0\nfor folder in  os.listdir(VALID_DIR) : \n    files = gb.glob(pathname= str( VALID_DIR + '//' + folder + '/*'))\n    class_names.append(folder)\n    class_count.append(len(files))\n    VALIDATION_EXAMPLES += len(files)\n\nplt.figure(figsize=(25,10))     \nsns.barplot(x = class_names, y=class_count).set_title(\"Distribution across classes in Valid set\")\nplt.show()\n\nprint(f'Total Train Examples = {VALIDATION_EXAMPLES}')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:42.856579Z","iopub.execute_input":"2021-12-12T04:10:42.857061Z","iopub.status.idle":"2021-12-12T04:10:43.068324Z","shell.execute_reply.started":"2021-12-12T04:10:42.857023Z","shell.execute_reply":"2021-12-12T04:10:43.067581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# diaplay 5 images from each class\nplt.figure(figsize=(12,12))\ni=0\nfor c in os.listdir(TRAIN_DIR):  \n    path = os.path.join(TRAIN_DIR,c)\n    for img in os.listdir(path):\n        img_array = cv2.cvtColor(cv2.imread(os.path.join(path,img)), cv2.COLOR_BGR2RGB) \n        plt.subplot(2,5,i+1)\n        plt.imshow(img_array)\n        if i%5 == 0:\n            plt.ylabel(c)\n        plt.xticks([])\n        plt.yticks([])\n        i += 1\n        if i%5 == 0:\n            break\n\nplt.tight_layout()        \nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:43.069964Z","iopub.execute_input":"2021-12-12T04:10:43.07045Z","iopub.status.idle":"2021-12-12T04:10:43.840055Z","shell.execute_reply.started":"2021-12-12T04:10:43.070411Z","shell.execute_reply":"2021-12-12T04:10:43.838842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = ImageDataGenerator(\n    # set input mean to 0 over the dataset\n    featurewise_center=False,\n    # set each sample mean to 0\n    samplewise_center=False,\n    # divide inputs by std of dataset\n    featurewise_std_normalization=False,\n    # divide each input by its std\n    samplewise_std_normalization=False,\n    # apply ZCA whitening\n    zca_whitening=False,\n    # epsilon for ZCA whitening\n    zca_epsilon=1e-06,\n    # randomly rotate images in the range (deg 0 to 180)\n    rotation_range=30,\n    # randomly shift images horizontally\n    width_shift_range=0.2,\n    # randomly shift images vertically\n    height_shift_range=0.2,\n    # set range for random shear\n    shear_range=0.2,\n    # set range for random zoom\n    zoom_range=0.3,\n    # set range for random channel shifts\n    channel_shift_range=0.,\n    # set mode for filling points outside the input boundaries\n    fill_mode='nearest',\n    # value used for fill_mode = \"constant\"\n    cval=0.,\n    # randomly flip images\n    horizontal_flip=True,\n    # randomly flip images\n    vertical_flip=False,\n    # set rescaling factor (applied before any other transformation)\n    rescale=None,\n    # set function that will be applied on each input\n    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n    # image data format, either \"channels_first\" or \"channels_last\"\n    data_format=None,\n    # fraction of images reserved for validation \n    # (strictly between 0 and 1)\n    validation_split=0.0,\n    # datatype\n    dtype=tf.float32,\n)\n\ntest_gen = ImageDataGenerator(\n    preprocessing_function= tf.keras.applications.resnet50.preprocess_input, \n    dtype=tf.float32\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:43.841082Z","iopub.execute_input":"2021-12-12T04:10:43.841512Z","iopub.status.idle":"2021-12-12T04:10:43.85175Z","shell.execute_reply.started":"2021-12-12T04:10:43.841457Z","shell.execute_reply":"2021-12-12T04:10:43.850938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batch = train_gen.flow_from_directory(\n    directory = TRAIN_DIR,\n    target_size = (IMG_SIZE,IMG_SIZE),\n    batch_size = BATCH_SIZE,\n    class_mode = 'sparse',\n    seed = SEED\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:43.852948Z","iopub.execute_input":"2021-12-12T04:10:43.85355Z","iopub.status.idle":"2021-12-12T04:10:45.009843Z","shell.execute_reply.started":"2021-12-12T04:10:43.853514Z","shell.execute_reply":"2021-12-12T04:10:45.008403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display 24 items  for a batch\nimgs, labels = next(train_batch)\ni = 0\nplt.figure(figsize=(20,7))\nfor img, label in zip(imgs, labels):\n    plt.subplot(2,8,i+1)\n    plt.imshow(img.astype('uint8'))\n    plt.xticks([])\n    plt.yticks([])\n    plt.xlabel(class_names[label.astype('int32')])\n    i+=1\n    if i == 16:\n        break\n        \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:45.011314Z","iopub.execute_input":"2021-12-12T04:10:45.011565Z","iopub.status.idle":"2021-12-12T04:10:47.968065Z","shell.execute_reply.started":"2021-12-12T04:10:45.011531Z","shell.execute_reply":"2021-12-12T04:10:47.967367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_batch = train_gen.flow_from_directory(\n    directory = VALID_DIR,\n    target_size = (IMG_SIZE,IMG_SIZE),\n    batch_size = BATCH_SIZE,\n    class_mode = 'sparse',\n    seed = SEED\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:47.970309Z","iopub.execute_input":"2021-12-12T04:10:47.971836Z","iopub.status.idle":"2021-12-12T04:10:48.083603Z","shell.execute_reply.started":"2021-12-12T04:10:47.971794Z","shell.execute_reply":"2021-12-12T04:10:48.082712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batch = test_gen.flow_from_directory(\n    directory = TEST_DIR,\n    target_size = (IMG_SIZE,IMG_SIZE),\n    batch_size = BATCH_SIZE,\n    class_mode = None,\n    seed = SEED\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:48.085202Z","iopub.execute_input":"2021-12-12T04:10:48.085497Z","iopub.status.idle":"2021-12-12T04:10:48.193116Z","shell.execute_reply.started":"2021-12-12T04:10:48.085449Z","shell.execute_reply":"2021-12-12T04:10:48.192219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_block(X, filters):\n    f1, f2, f3 = filters\n    X_copy = X\n    \n    # 1st Layer\n    X = layers.Conv2D(filters=f1, kernel_size=(1,1), strides=(1,1), padding='valid')(X)\n    X = layers.BatchNormalization(axis=3)(X)\n    X = layers.Activation('relu')(X)\n    \n    # 2nd Layer\n    X = layers.Conv2D(filters=f2, kernel_size=(3,3), strides=(1,1), padding='same')(X)\n    X = layers.BatchNormalization(axis=3)(X)\n    X = layers.Activation('relu')(X) \n    \n    # 3rd Layer\n    X = layers.Conv2D(filters=f3, kernel_size=(1,1), strides=(1,1), padding='valid')(X)\n    X = layers.BatchNormalization(axis=3)(X)\n    \n    # Add the Skip COnnection\n    X = layers.Add()([X, X_copy])\n    X = layers.Activation('relu')(X)\n    \n    return X","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:48.194797Z","iopub.execute_input":"2021-12-12T04:10:48.195103Z","iopub.status.idle":"2021-12-12T04:10:48.204993Z","shell.execute_reply.started":"2021-12-12T04:10:48.195062Z","shell.execute_reply":"2021-12-12T04:10:48.20373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_blocks(X, filters, s=2):\n    f1, f2, f3 = filters\n    X_copy = X\n    \n    # 1st Layer\n    X = layers.Conv2D(filters=f1, kernel_size=(1,1), strides=(s,s), padding='valid')(X)\n    X = layers.BatchNormalization(axis=3)(X)\n    X = layers.Activation('relu')(X)\n    \n    # 2nd Layer\n    X = layers.Conv2D(filters=f2, kernel_size=(3,3), strides=(1,1), padding='same')(X)\n    X = layers.BatchNormalization(axis=3)(X)\n    X = layers.Activation('relu')(X) \n    \n    # 3rd Layer\n    X = layers.Conv2D(filters=f3, kernel_size=(1,1), strides=(1,1), padding='valid')(X)\n    X = layers.BatchNormalization(axis=3)(X)\n    \n    ### match the dimension\n    X_copy = layers.Conv2D(filters=f3, kernel_size=(1,1), strides=(s,s), padding='valid')(X_copy)\n    X_copy = layers.BatchNormalization(axis=3)(X_copy)\n    \n    # Add the Skip COnnection\n    X = layers.Add()([X, X_copy])\n    X = layers.Activation('relu')(X)\n    \n    return X","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:48.207051Z","iopub.execute_input":"2021-12-12T04:10:48.207649Z","iopub.status.idle":"2021-12-12T04:10:48.220834Z","shell.execute_reply.started":"2021-12-12T04:10:48.207603Z","shell.execute_reply":"2021-12-12T04:10:48.219563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ResNet50():\n    X_input = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n    X = layers.ZeroPadding2D((3,3))(X_input)\n    \n    # Satge Conv1\n    X = layers.Conv2D(64, (7,7), strides=(2,2))(X)\n    X = layers.BatchNormalization(axis=3)(X)\n    X = layers.Activation('relu')(X) \n    X = layers.MaxPooling2D((3,3), strides=(2,2))(X)\n    \n    # stage Conv2_x\n    X = conv_blocks(X, filters=[64,64,256], s=1)\n    X = identity_block(X, filters=[64,64,256])\n    X = identity_block(X, filters=[64,64,256])\n    \n    # stage Conv3_x\n    X = conv_blocks(X, filters=[128,128,512], s=2)\n    X = identity_block(X, filters=[128,128,512])\n    X = identity_block(X, filters=[128,128,512])\n    X = identity_block(X, filters=[128,128,512])\n    \n    # stage Conv4_x\n    X = conv_blocks(X, filters=[256,256,1024], s=2)\n    X = identity_block(X, filters=[256,256,1024])\n    X = identity_block(X, filters=[256,256,1024])\n    X = identity_block(X, filters=[256,256,1024])\n    X = identity_block(X, filters=[256,256,1024])\n    X = identity_block(X, filters=[256,256,1024])\n    \n    # stage Conv5_x\n    X = conv_blocks(X, filters=[512,512,2048], s=2)\n    X = identity_block(X, filters=[512,512,2048])\n    X = identity_block(X, filters=[512,512,2048])\n    \n    \n    X = layers.AveragePooling2D((2,2))(X)\n    X = layers.Flatten()(X)\n    X = layers.Dense(2, activation='softmax', kernel_initializer='he_normal')(X)\n    \n    model = keras.Model(inputs=X_input, outputs=X, name='ResNet50')\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:48.222951Z","iopub.execute_input":"2021-12-12T04:10:48.22338Z","iopub.status.idle":"2021-12-12T04:10:48.242821Z","shell.execute_reply.started":"2021-12-12T04:10:48.223335Z","shell.execute_reply":"2021-12-12T04:10:48.241612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResNet50()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:48.245139Z","iopub.execute_input":"2021-12-12T04:10:48.245626Z","iopub.status.idle":"2021-12-12T04:10:51.570093Z","shell.execute_reply.started":"2021-12-12T04:10:48.245579Z","shell.execute_reply":"2021-12-12T04:10:51.569331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lr_schedule(epoch):\n    lr = 1e-3\n    if epoch > 40:\n        lr *= 0.5e-3\n    elif epoch > 30:\n        lr *= 1e-3\n    elif epoch > 20:\n        lr *= 1e-2\n    elif epoch > 10:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr\nlr_scheduler = LearningRateScheduler(lr_schedule)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:51.571427Z","iopub.execute_input":"2021-12-12T04:10:51.571736Z","iopub.status.idle":"2021-12-12T04:10:51.578317Z","shell.execute_reply.started":"2021-12-12T04:10:51.571695Z","shell.execute_reply":"2021-12-12T04:10:51.577634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=keras.optimizers.Adam(lr=lr_schedule(0)), \n    loss='sparse_categorical_crossentropy', \n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:10:51.579617Z","iopub.execute_input":"2021-12-12T04:10:51.580181Z","iopub.status.idle":"2021-12-12T04:10:51.603993Z","shell.execute_reply.started":"2021-12-12T04:10:51.580142Z","shell.execute_reply":"2021-12-12T04:10:51.603302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}